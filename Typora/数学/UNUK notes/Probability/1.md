# Basic definition

> **Definition-sample space**
>
> The **set of possible outcomes** for a **random experiment** is known as the **sample space** and is typically denoted as $\Omega$.



> **Definition-random variable**
>
> A **random variable**, $X$, is a function of the outcome of the experiment which maps from the sample space to a set $S$. That is
> $$
> X:\Omega\rightarrow S
> $$
> For $\omega \in \Omega $ denotes an experiment outcome then the set $S$ can be written as:
> $$
> S=\left\{X(\omega):\omega\in \Omega\right\}
> $$
> which can be divided into two kinds:
>
> > **Definition-Discrete random variables**
> >
> > For the case that $X$ can take only a finite or countable number of values and we say that $X$ is a **discrete random variable**.
>
> > **Definition-Continuous Random Variables**
> >
> > For the case that the sample space Î© is an uncountable set, the random variable $X$ is known as a **continuous random variable**.



> **Definition-Joint Cumulative Distribution Function**
>
> Suppose that $X$ and $Y$ are two random variables. The **joint cumulative distribution function** of $X$ and $Y$ is:
> $$
> F_{X,Y}(x,y)=\mathbb{P}(X\le x,Y\le y) \quad x,y\in\mathbb{R}
> $$



> **Definition-Joint Probability Density Function**
>
> Suppose that $F_{X,Y}(x,y)$ is the joint cumulative distribution function for the pair of random variables $(X,Y)$.
>
> If there exists a function $f_{X,Y}$ such that:
> $$
> F_{X,Y}(x,y)=\int_{-\infty}^y\int_{-\infty}^xf_{X,Y}(u,v)dudv
> $$
> then $f_{X,Y}$ is the **joint probability density function** of $X$ and $Y$ (joint PDF)
>
> > [!NOTE]
> > $$
> > f_{X,Y}(x,y)=\frac{\partial^2F_{X,Y}(x,y)}{\partial x\partial y}
> > $$



> **Definition-Marginal Probability Density Function**
>
> Suppose that $f_{X,Y}(x,y)$ is the joint probability density function of the random variables $X$ and $Y$.
>
> The **marginal probability density function **of $X$ and $Y$ are
> $$
> f_X(x)=\int _{-\infty}^{\infty}f_{X,Y}(x,y)dy
> $$
>  and
> $$
> f_Y(y)=\int _{-\infty}^{\infty}f_{X,Y}(x,y)dx
> $$



> **Definition- Marginal Cumulative Distribution Function**
>
> as follows
> $$
> F_X(x)=F_{X,Y}(x,\infty)\\F_Y(y)=F_{X,Y}(\infty,y)
> $$
> 



> **Definition-Independence**
>
> If following equation is satisfied $\forall x,y\in \mathbb{R}$ for random variables $X,$$Y$:
> $$
> F_{X,Y}(x,y)=F_X(x)\cdot F_Y(y)\\
> \text{equivalent to} \quad f_{X,Y}(x,y)=f_X(x)\cdot f_Y(y)\\
> \text{equivalent to} \quad \mathbb{P}(X\le x \quad\cap\quad Y\le y)=\mathbb{P}(X\le x)\cdot \mathbb{P}(Y\le y )
> $$
> call $X$ and $Y$ independent.



> 

#  Independent Random Variables

Suppose that $X$ and $Y$ are independent random variables with probability density functions $f_X(x) $and $f_Y(y)$, respectively. The cumulative distribution function of $Z=X+Y$ is
$$
F_Z(z)=\int _{-\infty}^\infty F_X(x)\cdot F_Y(z-x)dx
$$
