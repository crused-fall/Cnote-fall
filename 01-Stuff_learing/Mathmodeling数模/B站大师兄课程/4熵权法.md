# 熵权法介绍

![image-20250818155042666](C:\Users\19006\AppData\Roaming\Typora\typora-user-images\image-20250818155042666.png)

**如何分配权重**

主观分析$\rightarrow$ **层次分析法**

客观赋值$\rightarrow$**熵权法**

------

# 定义

## 概率与信息量

<img src="C:\Users\19006\AppData\Roaming\Typora\typora-user-images\image-20250818160637853.png" alt="image-20250818160637853" style="zoom: 150%;" />概率P(x)越小，信息量I(x)越大；
概率P(x)越大，信息量I(x)越小：

**定义**:$I(x)=-ln(p(x))$



## 信息熵与信息量

**信息熵**：平均而言发生一个事件我们得到的信息量大小.（得到的信息越多，已掌握的信息越少）
$$
H(X)=\sum_{i\operatorname{=}I}^{n}\left[p\left(x_{i}\right)I\left(x_{i}\right)\right]=
-\sum_{i\operatorname{=}I}^{n}\left[p\left(x_{i}\right)\ln\left(p\left(x_{i}\right)\right)\right]
$$

> [!NOTE]
>
> 本质为**对信息量的期望值**



**熵权法**：是一种可以对多对象、多指标进行综合评价的方法，其评价依据来源于数据本身，几乎不受主观因素的干扰.

**基本思想**：
$$
\text{信息熵小}\Rightarrow\text{得到的信息少}\&\text{掌握的信息多}\Rightarrow\text{这组信息更靠谱}\Rightarrow\text{权重大}
$$


通过简单的推导，可得
$$
p\left(x_{1}\right)=p\left(x_{2}\right)=\cdots=p\left(x_{n}\right)=\frac{1}{n}
$$
时，$H(x)_{max}=\ln x$

# 过程

## 第一步：指标正项化处理

**极小型**：
$$
x_{new}=\max_i{x_i}-x
$$
或者
$$
x_{new}=\frac{1}{x}
$$


**中间型**：
$$
x_{new}=1-\frac{|x-x_{best}|}{\max_{i}{|x_i-x_{best}|}}
$$


**区间型**：
$$
\tilde{x}_i=\begin{cases}1-\frac{a-x_i}M&,x_i<a\\1&,a\leq x_i\leq b\\1-\frac{x_i-b}{M}&,x_i>b\end{cases}
$$
where：
$$
M=\max\left\{a-\min\left\{x_i\right\},\max\left\{x_i\right\}-b\right\}
$$


## 第二步：标准化处理

对于$n$个评价对象，$m$个**正向化**指标，构成矩阵
$$
X=\begin{bmatrix}x_{11}&x_{12}&\cdots&x_{1m}\\x_{21}&x_{22}&\cdots&x_{2m}\\\vdots&\vdots&\ddots&\vdots\\x_{n1}&x_{n2}&\cdots&x_{nm}\end{bmatrix}
$$


将其标准化为$Z$:
$$
z_{ij}=\frac{x_{ij}}{\sqrt{\sum_{i\operatorname{=}1}^nx_{ij}^2}}
$$

> [!NOTE]
>
> 使同一列（同一指标）的元素平方和为1



若其中有**负**元素，则将其改为：
$$
\tilde{z}_{ij}=\frac{x_{ij}-\min\left\{x_{1j},x_{2j},\cdots,x_{nj}\right\}}{\max\left\{x_{1j},x_{2j},\cdotp\cdotp\cdotp,x_{nj}\right\}-\min\left\{x_{1j},x_{2j},\cdotp\cdotp\cdotp,x_{nj}\right\}}
$$

> [!NOTE]
>
> 将负数正则化

得到：
$$
\tilde{Z}=\begin{bmatrix}\tilde{z}_{11}&\tilde{z}_{12}&\cdots&\tilde{z}_{1m}\\\tilde{z}_{21}&\tilde{z}_{22}&\cdots&\tilde{z}_{2m}\\\vdots&\vdots&\ddots&\vdots\\\tilde{z}_{n1}&\tilde{z}_{n2}&\cdots&\tilde{z}_{nm}\end{bmatrix}
$$


## 第三步：计算信息熵和熵权

计算信息熵：
$$
e_{j}=-\frac{1}{\ln n}\sum_{i=1}^{n}p_{ij}\ln\left(p_{ij}\right)\left(j=1,2,\cdots,m\right)
$$


信息效用值：
$$
d_j=1-e_j
$$


归一化信息效用值得到熵权：
$$
W_{j}=\frac{d_{j}}{\sum_{j\:=\:1}^{m}d_{j}}\quad\left(j=1,2,\cdots,m\right)
$$
